{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelNet Classification with RotationNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    # normalization for pretrained networks \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual shuffling\n",
    "this function is used to shuffle the training dataset while maintaining the views of an object together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataloader(dataloader, num_views):\n",
    "\n",
    "    num_samples = len(dataloader.dataset.imgs)//num_views\n",
    "\n",
    "    # initializing vector of indices first row will correspond to indices of firts view of each element\n",
    "    # second row to second view and so on\n",
    "    indices = np.zeros( ( num_views, num_samples ) ).astype('int')\n",
    "    indices[0] = np.random.permutation(num_samples) * num_views\n",
    "\n",
    "    # adding following indices to the rows\n",
    "    for i in range(1,num_views):\n",
    "        indices[i] = indices[0] + i\n",
    "\n",
    "    # flattening the vector along its columns       \n",
    "    indices = indices.flatten(order='F')\n",
    "\n",
    "    #applying the modifications to the dataloader directly\n",
    "    dataloader.dataset.imgs = [dataloader.dataset.imgs[i] for i in indices]\n",
    "    dataloader.dataset.samples = dataloader.dataset.imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# setting dataset to use and version (1 w upright 2 w/o upright)\n",
    "num_classes = 40\n",
    "version = \"2\"\n",
    "\n",
    "# setting number of views for each object (differs from versions)\n",
    "if version==\"1\":\n",
    "    num_views = 12\n",
    "    viewpoint_candidate = np.load('vcand_case1.npy')\n",
    "else:\n",
    "    num_views = 20\n",
    "    viewpoint_candidate = np.load('vcand_case2.npy')\n",
    "\n",
    "# creating ImageFolder Datasets\n",
    "train_dataset = ImageFolder(f'../content/datasets/ModelNet{num_classes}_png_v{version}/train', transforms)\n",
    "test_dataset = ImageFolder(f'../content/datasets/ModelNet{num_classes}_png_v{version}/test', transforms)\n",
    "\n",
    "# in version 1 validation set is not present since we only have a small subset of ModelNet so we are going to use test set also as validation\n",
    "if version==\"1\":\n",
    "    validation_dataset = ImageFolder(f'../content/datasets/ModelNet{num_classes}_png_v{version}/test', transforms)\n",
    "else:\n",
    "    validation_dataset = ImageFolder(f'../content/datasets/ModelNet{num_classes}_png_v{version}/validation', transforms)\n",
    "\n",
    "# dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, 10*num_views, shuffle=False,  num_workers=0)\n",
    "validation_dataloader = DataLoader(validation_dataset, 10*num_views, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, 10*num_views, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the neural networks\n",
    "\n",
    "### VGG16 (Configuration D)\n",
    "Implementration of the VGG16 architecture for the first part of the pipeline  \n",
    "We decided to leave the code since it was done but we do not use it since it was too time consuming to train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d, ReLU, MaxPool2d, Linear, Dropout\n",
    "\n",
    "class VGG16_bn_manual(Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.network = Sequential(\n",
    "            \n",
    "            # Definition of first block\n",
    "\n",
    "            # first layer\n",
    "            Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=64),\n",
    "            ReLU(),\n",
    "            # second layer\n",
    "            Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=64),\n",
    "            ReLU(),\n",
    "            # Maxpool_1\n",
    "            MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        \n",
    "            # Definition of second block\n",
    "\n",
    "            # third layer\n",
    "            Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=128),\n",
    "            ReLU(),\n",
    "            # fourth layer\n",
    "            Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=128),\n",
    "            ReLU(),\n",
    "\n",
    "            # Maxpool_2\n",
    "            MaxPool2d(kernel_size = 2, stride = 2),\n",
    "\n",
    "            # Definition of third block\n",
    "\n",
    "            # fifth layer\n",
    "            Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=256),\n",
    "            ReLU(),\n",
    "            # sixth layer\n",
    "            Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=256),\n",
    "            ReLU(),\n",
    "            # seventh layer\n",
    "            Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=256),\n",
    "            ReLU(),\n",
    "\n",
    "            # Maxpool_3\n",
    "            MaxPool2d(kernel_size = 2, stride = 2),\n",
    "\n",
    "            # Definition of fourth block\n",
    "\n",
    "            # eighth layer\n",
    "            Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=512),\n",
    "            ReLU(),\n",
    "            # ninth layer\n",
    "            Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=512),\n",
    "            ReLU(),\n",
    "            # tenth layer\n",
    "            Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=512),\n",
    "            ReLU(),\n",
    "\n",
    "            # Maxpool_4\n",
    "            MaxPool2d(kernel_size = 2, stride = 2),\n",
    "\n",
    "            # Definition of fifth block\n",
    "\n",
    "            # eleventh layer\n",
    "            Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=512),\n",
    "            ReLU(),\n",
    "            # twelfth layer\n",
    "            Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=512),\n",
    "            ReLU(),\n",
    "            # thirteenth layer\n",
    "            Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(num_features=512),\n",
    "            ReLU(),\n",
    "\n",
    "            # Maxpool_5\n",
    "            MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        # Classification Layer\n",
    "        self.classifier = Sequential(\n",
    "                Dropout(),\n",
    "                Linear(7*7*512, 4096),\n",
    "                ReLU(),\n",
    "                Dropout(),\n",
    "                Linear(4096, 4096),\n",
    "                ReLU(),\n",
    "                Linear(4096, num_classes),\n",
    "            )   \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x).reshape((x.shape[0], -1)) # added flatten layer\n",
    "        x = self.classifier(x)\n",
    "        # returns the logits\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (Configuration D) Pretrained\n",
    "used to fine-tune the VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Sequential, ReLU,  Linear, Dropout\n",
    "import torchvision.models as models\n",
    "class VGG_16_pretrained(Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG_16_pretrained, self).__init__()\n",
    "        vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)        \n",
    "        \n",
    "        self.features = vgg16.features\n",
    "        self.classifier = Sequential(\n",
    "            Dropout(),\n",
    "            Linear(7*7*512, 4096),\n",
    "            ReLU(),\n",
    "            Dropout(),\n",
    "            Linear(4096, 4096),\n",
    "            ReLU(),\n",
    "            Linear(4096, num_classes),\n",
    "        )\n",
    "        # Freezing Pretrained Weigths\n",
    "        for layer in self.features.parameters():\n",
    "            layer.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x).reshape((x.shape[0], -1)) # added flatten layer\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Functions\n",
    "#### Function used to calculate loss and accuracy on validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import log_softmax\n",
    "\n",
    "def calculate_accuracy(dataloader, network, num_classes, num_views, viewpoint_candidate):\n",
    "\n",
    "    # verifying if cuda is available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # creating iterator\n",
    "    iterator = tqdm(dataloader)\n",
    "\n",
    "    # putting the network on evaluation mode\n",
    "    network.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        labels = []\n",
    "        outputs = []\n",
    "\n",
    "        for batch_data, batch_labels in iterator:\n",
    "\n",
    "            # moving batch to device\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)        \n",
    "            \n",
    "            # forward pass\n",
    "            batch_output = network(batch_data)\n",
    "\n",
    "            # adding labels and logits predictions to array\n",
    "            outputs.append(batch_output)\n",
    "            labels.append(batch_labels)\n",
    "\n",
    "        # concatenating to obtain a single tensor\n",
    "        labels = torch.cat(labels, axis=0) \n",
    "        outputs = torch.cat(outputs, axis=0)\n",
    "\n",
    "        # removing multiple labels due to multiple views\n",
    "        labels= labels[0:-1:num_views]\n",
    "\n",
    "        # reshaping the output\n",
    "        outputs = outputs.reshape(-1, num_classes + 1 )\n",
    "\n",
    "        # using softmax to obtain probabilities then the logarithm to simplify calculations (sum instead of division)\n",
    "        log_probs = log_softmax( outputs, dim = 1)\n",
    "\n",
    "        # calculating last equation of eq.5 in RotationNet paper\n",
    "        log_p_vi_N_1 = log_probs[ :, -1 ].unsqueeze(1).expand(-1 , num_classes)\n",
    "        log_p_vi_y = log_probs[ :, :-1 ]\n",
    "        summation = log_p_vi_y - log_p_vi_N_1 #called summation because using logarithms to calculate the division\n",
    "\n",
    "        # reshaping and conversion (necessary to work with numpy) for score calculations with candidate views\n",
    "        summation = summation.reshape( -1, num_views*num_views, num_classes )\n",
    "        summation = summation.cpu().numpy().transpose( 1, 2, 0 )\n",
    "        \n",
    "        # initializing scores for all views \n",
    "        scores = np.zeros( ( viewpoint_candidate.shape[0], num_classes, labels.shape[0]))\n",
    "\n",
    "        # initializing scores for best view namely eq.6 in RotationNet paper\n",
    "        best_scores = torch.zeros( ( labels.shape[0], num_classes))\n",
    "\n",
    "        # calculating scores from eq.6 in RotationNet paper\n",
    "        # summing the scores since we are using the logarithms this still need argmax\n",
    "        for i in range(viewpoint_candidate.shape[0]):\n",
    "            for j in range(viewpoint_candidate.shape[1]):\n",
    "                scores[i] = scores[i] + summation[viewpoint_candidate[i][j]*num_views + j]\n",
    "        \n",
    "        # computing argmax to find best viewpoint and considering savinng its scores as the best one \n",
    "        for i in range(labels.shape[0]):\n",
    "            # dividing by num_classes is needed to find the starting index of the best viewpoint \n",
    "            best_viewpoint_idx = np.argmax( scores[ :, :, i] ) // num_classes\n",
    "            best_scores[ i ] = torch.FloatTensor( scores[ best_viewpoint_idx, :, i ] )\n",
    "        \n",
    "        # finding best class prediction\n",
    "        pred = torch.argmax(best_scores, dim=1).to(device)\n",
    "        \n",
    "        # calculating accuracy\n",
    "        accuracy = torch.sum(pred == labels)/len(labels)    \n",
    "    return  accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training epoch\n",
    "This function will do a single epoch of the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(dataloader, network, loss_fn, optimizer, num_classes, num_views, viewpoint_candidate):\n",
    "    \n",
    "    # verifying if cuda is available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # creating iterator\n",
    "    iterator = tqdm(dataloader)\n",
    "\n",
    "    # putting the network on training mode\n",
    "    network.train()\n",
    "    \n",
    "    for batch_data, batch_labels in iterator:\n",
    "                \n",
    "        # definyng number of samples\n",
    "        num_samples = batch_data.size(0) // num_views\n",
    "\n",
    "        # moving batch to device\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)        \n",
    "        \n",
    "        # forward pass\n",
    "        batch_outputs = network(batch_data)\n",
    "\n",
    "        # reshaping the output\n",
    "        batch_outputs = batch_outputs.reshape(-1, num_classes + 1 )\n",
    "\n",
    "        # using softmax to obtain probabilities then the logarithm to simplify calculations (sum instead of division)\n",
    "        log_probs = log_softmax( batch_outputs, dim = 1)\n",
    "\n",
    "        # calculating last equation of eq.5 in RotationNet paper\n",
    "        log_p_vi_N_1 = log_probs[ :, -1 ].unsqueeze(1).expand(-1 , num_classes)\n",
    "        log_p_vi_y = log_probs[ :, :-1 ]\n",
    "        summation = log_p_vi_y - log_p_vi_N_1 #called summation because using logarithms to calculate the division\n",
    "\n",
    "        # reshaping and conversion (necessary to work with numpy) for score calculations with candidate views\n",
    "        summation = summation.reshape( -1, num_views*num_views, num_classes )\n",
    "        summation = summation.data.cpu().numpy().transpose( 1, 2, 0 )\n",
    "\n",
    "        # initializing modified labels(with viewpoint) initially set to incorrect view\n",
    "        mod_labels = torch.LongTensor( batch_labels.shape[0] * num_views )    \n",
    "        for i in range(mod_labels.shape[0]):\n",
    "            # since normal label [0,num_classes-1] incorrect view will be num_classes\n",
    "            mod_labels[i] = num_classes \n",
    "        \n",
    "        # initializing scores for all views \n",
    "        scores = np.zeros( ( viewpoint_candidate.shape[0], num_classes, num_samples))\n",
    "\n",
    "        # calculating scores from eq.6 in RotationNet paper\n",
    "        # summing the scores since we are using the logarithms this stil need argmax\n",
    "        for i in range(viewpoint_candidate.shape[0]):\n",
    "            for j in range(viewpoint_candidate.shape[1]):\n",
    "                scores[i] = scores[i] + summation[viewpoint_candidate[i][j]*num_views + j]\n",
    "        # computing argmax to find best viewpoint and considering savinng its scores as the best one \n",
    "        for i in range(num_samples):                        \n",
    "            best_viewpoint_class_idx = np.argmax( scores[ :, batch_labels[ i * num_views ], i ] )\n",
    "            for j in range(viewpoint_candidate.shape[1]):\n",
    "                    mod_labels[ i * num_views * num_views + viewpoint_candidate[ best_viewpoint_class_idx ][ j ] * num_views + j ] = batch_labels[ i * num_views ]\n",
    "\n",
    "        # moving modified labels to device to have everything on the same one\n",
    "        mod_labels = mod_labels.to(device)\n",
    "\n",
    "        # compute loss\n",
    "        train_loss = loss_fn(batch_outputs, mod_labels)\n",
    "\n",
    "        # logging training loss\n",
    "        wandb.log({\"train_loss\": train_loss})\n",
    "        \n",
    "        # bacward pass\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # viewing batch results\n",
    "        iterator.set_description(f\"Train loss: {train_loss.detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop\n",
    "This function will execute the entire training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "def training_Loop(network, train_dl, val_dl, epochs, num_classes, num_views, viewpoint_candidate):\n",
    "    \n",
    "    # defining loss functions\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    # using optimizer only on finetunable parameters (with manual model on all parameters)\n",
    "    optimizer = SGD(filter(lambda p: p.requires_grad, network.parameters()), lr=1e-2, momentum=0.90, weight_decay=1e-4)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    network.to(device)\n",
    "\n",
    "    #best_val_loss = np.inf\n",
    "    best_val_acc = 0\n",
    "\n",
    "    # iterating through the epochs\n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch: '+str(epoch))\n",
    "\n",
    "        # using variable learning rate too few epochs to be effective\n",
    "        #if (epoch % 40)==0 :\n",
    "            #lr = 1e-2 * (0.1 ** (epoch // 40))\n",
    "            #print(f\"\\nSetting learning rate to: {lr}\\n\")  \n",
    "            #for param_group in optimizer.param_groups:\n",
    "                #param_group['lr'] = lr\n",
    "\n",
    "        # TRAINING\n",
    "        print(\"TRAINING PHASE\")\n",
    "\n",
    "        # shuffilng train dataloader\n",
    "        shuffle_dataloader(train_dl, num_views)\n",
    "\n",
    "        # executing a training epoch\n",
    "        training_epoch(train_dl, network, loss_fn, optimizer, num_classes, num_views, viewpoint_candidate)\n",
    "\n",
    "        # VALIDATION\n",
    "        print(\"VALIDATION PHASE\")\n",
    "     \n",
    "        # calculating loss and accuracy\n",
    "        val_acc = calculate_accuracy(val_dl, network, num_classes, num_views, viewpoint_candidate)\n",
    "        \n",
    "        # logging validation results\n",
    "        wandb.log({\"epoch\": epoch,\n",
    "                   \"validation_accuracy\": val_acc,                \n",
    "                   \"validation_error\": 1-val_acc})\n",
    "\n",
    "        # visualizing validation results\n",
    "        print(f\"Validation accuracy: {val_acc.detach().cpu().numpy()}\")       \n",
    "\n",
    "        # updating and saving the best model\n",
    "        if val_acc >= best_val_acc:\n",
    "            print(\"Saved Model\")\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(network.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "#### Initilizing Data Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"RotationNet_Modelnet_40\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"dataset\": \"ModelNet40_case_2\",\n",
    "    \"epochs\": 60,\n",
    "    }\n",
    ")\n",
    "wandb.define_metric(\"epoch\")\n",
    "\n",
    "wandb.define_metric(\"validation_accuracy\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"validation_error\", step_metric=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting training loop and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_16_pretrained((num_classes+1)*num_views)\n",
    "epochs = 60\n",
    "\n",
    "training_Loop(model, train_dataloader, validation_dataloader, epochs, num_classes, num_views, viewpoint_candidate)\n",
    "# closing logging at the end of the run\n",
    "wandb.finish()\n",
    "# testing\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "val_accuracy = calculate_accuracy(validation_dataloader, model, num_classes, num_views, viewpoint_candidate)\n",
    "print(\"Validation Accuracy : \"+str(val_accuracy))\n",
    "\n",
    "test_accuracy = calculate_accuracy(test_dataloader, model, num_classes, num_views, viewpoint_candidate)\n",
    "print(\"Test Accuracy : \"+str(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
